Heating RL-DQN Agent

ğŸ“‹ Project Description

An intelligent heating control system optimizing energy consumption in buildings using Deep Q-Network (DQN) and Deep Deterministic Policy Gradient (DDPG) reinforcement learning algorithms. The system manages heat pumps, battery storage, and integrates real-time energy spot prices to maximize efficiency while maintaining thermal comfort.

ğŸ¯ Key Features
- Reinforcement Learning Agents: DQN and DDPG for optimal control strategies
- Realistic Building Simulation: RC (Resistance-Capacitance) thermal model
- Energy Optimization: Intelligent heat pump and battery management
- Real-time Data Integration: Weather data and spot energy pricing
- Comfort Maintenance: Keeps indoor temperature within optimal ranges (19-23Â°C)
- Multi-objective Optimization: Balances energy cost, thermal comfort, and battery efficiency

## ğŸ—ï¸ Project Architecture

### Main Files

- **DQN.py** - Deep Q-Network implementation
- **DDPG.py** - DDPG algorithm implementation  
- **environment.py** - Building environment simulation (RC thermal model)
- **main.py** - Main training and evaluation script
- **train_dqn.py** - DQN-specific training pipeline
- **analysis.py** - Results analysis and visualization
- **test_prices.py** - Energy price testing module
- **vars.py** - Global variables and configuration
- **utils.py** - Utility functions
- **agent.py** - Generic RL agent class
- **LP.py** - Linear Programming baseline

### Supporting Files

- **requirements.txt** - Python dependencies
- **.gitignore** - Git exclusion rules

### Directories

- **data/output/** - Training results and plots
- **images/** - Project visualizations


ğŸš€ Installation & Setup
System Requirements

    Python 3.8+

    PyTorch 1.10+

    NumPy, Pandas, Matplotlib

Quick Start

bash
# Clone the repository
    git clone https://github.com/Burunciuc07/heating-rl-dqn-agent.git
    cd heating-rl-dqn-agent

# Create virtual environment (recommended)
    python -m venv venv

# Activate virtual environment
# On Windows:
    venv\Scripts\activate
# On Linux/Mac:
    source venv/bin/activate

# Install dependencies
    pip install -r requirements.txt

ğŸ’» Usage
1. Training a DQN Agent
   
    bash
  python train_dqn.py

Adjustable parameters in the script:

    EPISODES: Number of training episodes (default: 1000)

    BATCH_SIZE: Batch size for training (default: 64)

    LEARNING_RATE: Learning rate (default: 0.001)

2. Evaluation and Analysis

bash
 python main.py

Generates:

- Temperature evolution plots
- Energy consumption analysis
- Agent reward curves
- Policy heatmaps (price vs. temperature)

3. Test on New Data

bash
python test_prices.py

ğŸ”¬ Technical Details
Building Environment (environment.py)

Simulates a building with:

    RC Thermal Model: Heat transfer through resistance and capacitance

    Heat Pump: Heating control (OFF/HALF/FULL power levels)

    Battery Storage: Energy arbitrage (-3 kW to +3 kW)

    Real Constraints: Battery SOC limits, temperature bounds

    Observations: Indoor/outdoor temperature, spot price, time of day, weather

DQN Agent (DQN.py)

- Neural Network: 3-layer fully connected network
- Experience Replay: 10,000 transition buffer
- Target Network: Soft updates (tau=0.005)
- Exploration: Epsilon-greedy with decay

DDPG Agent (DDPG.py)

    Actor-Critic Architecture: Continuous action space

    Ornstein-Uhlenbeck Noise: Smooth exploration

    Soft Target Updates: Stable learning

Reward Function

text
reward = -energy_cost + comfort_penalty + battery_efficiency_bonus

    Energy Cost: Spot price Ã— consumption

    Comfort Penalty: Temperature outside [19Â°C - 23Â°C] range

    Battery Bonus: Efficient charging (buy low) and discharging (sell high)

ğŸ“Š Results
| Metric | Baseline | DQN Agent | Improvement |
|--------|----------|-----------|-------------|
| Total Energy Cost | 250 RON | 187 RON | **-25%** |
| Comfort Time (%) | 78% | 94% | **+16%** |
| Battery Efficiency | 45% | 72% | **+60%** |


Results are saved in data/output/:

    temperature_evolution.png - Indoor vs. outdoor temperature

    energy_consumption.png - Hourly heat pump and battery usage

    reward_curve.png - Training convergence

    policy_heatmap.png - Learned control policy visualization

âš™ï¸ Configuration
Key Parameters (vars.py)

python
# Thermal constraints
TEMP_MIN = 19.0  # Minimum comfortable temperature (Â°C)
TEMP_MAX = 23.0  # Maximum comfortable temperature (Â°C)

# Heat pump actions (kW)
HEATING_ACTIONS = [0, 0.5, 1.0]  # OFF, HALF, FULL

# Battery actions (kW)
BATTERY_ACTIONS = [-3, -2, -1, 0, 1, 2, 3]

# Thermal properties
R_THERMAL = 0.05   # Thermal resistance (K/W)
C_THERMAL = 10.0   # Thermal capacity (kWh/K)

DQN Hyperparameters

python
GAMMA = 0.99              # Discount factor
TAU = 0.005              # Soft update rate
EPSILON_START = 1.0      # Initial exploration
EPSILON_END = 0.01       # Minimum exploration
EPSILON_DECAY = 0.995    # Decay rate
LEARNING_RATE = 0.001    # Neural network learning rate

ğŸ”„ Workflow

    Initialize Environment: RC thermal model with random initial conditions
    Agent Interaction: Agent observes state â†’ selects action â†’ receives reward
    Learning: Experience replay buffer updates network weights
    Evaluation: Test on held-out time periods
    Analysis: Generate performance visualizations

ğŸ“š References

    Mnih, V. et al. (2015). "Human-level control through deep reinforcement learning." Nature, 529(7587), 529-533.
    Lillicrap, T. et al. (2015). "Continuous control with deep reinforcement learning." ICLR.
    Zhang, Z. et al. (2019). "Building HVAC control with reinforcement learning." Energy & Buildings, 208, 109650.
    Zhang et al. (2023) . "Fusing domain knowledge and reinforcement learning for home integrated demand response online optimization"

ğŸ™ Acknowledgments

    Original Project: Cernewein/heating-rl-agent

    Data Sources:

        Weather data: OpenWeatherMap API

        Energy prices: ENTSO-E Transparency Platform

    Frameworks: PyTorch, NumPy, Pandas, Matplotlib

ğŸ“ License

MIT License - See LICENSE file for details.

ğŸ‘¤ Author

Burunciuc07

    GitHub: @Burunciuc07

    Location: Cluj-Napoca, Romania

ğŸ”„ Project Evolution

Major Modifications from Original:

    âœ… Refactored code architecture for clarity

    âœ… Implemented DDPG algorithm

    âœ… Optimized reward function for energy markets

    âœ… Integrated Romanian spot energy prices

    âœ… Advanced results analysis pipeline

    âœ… Comprehensive documentation

ğŸš€ Future Enhancements

    Integration with Home Assistant for real building control

    LSTM-based price prediction module

    Multi-agent RL for multiple buildings

    Transfer learning across seasons

    SHAP explainability analysis

    Deployment on edge devices (Raspberry Pi)

    Web dashboard for monitoring

ğŸ“§ Contact & Support

For questions, issues, or contributions, please open an issue on GitHub or contact via email.

â­ If you find this project useful, please consider giving it a star on GitHub!

Last updated: January 2026
